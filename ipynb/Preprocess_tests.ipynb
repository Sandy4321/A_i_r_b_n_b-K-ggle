{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOADING LIBRARIES\n",
    "%matplotlib inline\n",
    "#%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "#import pylab as pl\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import sklearn\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from sklearn import cross_validation, metrics, neighbors\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC, SVR, NuSVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA, RandomizedPCA, TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from scipy import sparse\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "gc.enable()\n",
    "np.random.seed(455)\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users in train:  213451\n",
      "Total users in test:  62096\n"
     ]
    }
   ],
   "source": [
    "#LOADING AND JOINING THE DATA\n",
    "\n",
    "import os\n",
    "import glob\n",
    "#print (glob.glob(\"../kaggle_data/*.csv\"))\n",
    "\n",
    "df_train = pd.read_csv('../kaggle_data/train_users_2.csv')\n",
    "df_test = pd.read_csv('../kaggle_data/test_users.csv')\n",
    "labels = df_train['country_destination'].values\n",
    "\n",
    "\n",
    "id_test = df_test['id']\n",
    "piv_train = df_train.shape[0]\n",
    "piv_test = df_test.shape[0]\n",
    "print (\"Total users in train: \",piv_train)\n",
    "print (\"Total users in test: \",piv_test)\n",
    "\n",
    "df_test['country_destination'] = -1\n",
    "\n",
    "#Creating a DataFrame with train+test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "#Filling nan\n",
    "df_all = df_all.fillna(-1)\n",
    "\n",
    "del df_test, df_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new columns created\n"
     ]
    }
   ],
   "source": [
    "#####Feature engineering#######\n",
    "\n",
    "#date_account_created\n",
    "dac = np.vstack(df_all.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "df_all['dac_year'] = dac[:,0]\n",
    "df_all['dac_month'] = dac[:,1]\n",
    "df_all['dac_day'] = dac[:,2]\n",
    "\n",
    "\n",
    "#timestamp_first_active\n",
    "tfa = np.vstack(df_all.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)\n",
    "df_all['tfa_year'] = tfa[:,0]\n",
    "df_all['tfa_month'] = tfa[:,1]\n",
    "df_all['tfa_day'] = tfa[:,2]\n",
    "\n",
    "#Age\n",
    "av = df_all.age.values\n",
    "df_all['age'] = np.where(np.logical_or(av<14, av>100), -1, av)\n",
    "\n",
    "#One-hot-encoding features\n",
    "ohe_feats = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']\n",
    "for f in ohe_feats:\n",
    "    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n",
    "    df_all = df_all.drop([f], axis=1)\n",
    "    df_all = pd.concat((df_all, df_all_dummy), axis=1)\n",
    " \n",
    "\n",
    "#Removing columns that won't be included into model\n",
    "df_all = df_all.drop(['id', 'date_first_booking','country_destination','date_account_created',\n",
    "                     'timestamp_first_active',], axis=1)\n",
    "\n",
    "#print (\"\\nVar names:\\n\",df_all.columns.values)\n",
    "print (\"new columns created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.00000000e+00   2.01000000e+03   6.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  3.80000000e+01   2.01100000e+03   5.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  5.60000000e+01   2.01000000e+03   9.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [ -1.00000000e+00   2.01400000e+03   9.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [ -1.00000000e+00   2.01400000e+03   9.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.90000000e+01   2.01400000e+03   9.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[ 7  7 10 ...,  7  7  7]\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into test and train\n",
    "vals = df_all.values\n",
    "print (df_all.values)\n",
    "X = vals[:piv_train]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)   \n",
    "print (y)\n",
    "X_test = vals[piv_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_PROCS = 8\n",
    "\n",
    "def unwrapLS(arg, **kwarg):\n",
    "    return CLFLS.oneFit(*arg, **kwarg)\n",
    "\n",
    "class CLFLS(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, X, y, param, final):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.param = param        \n",
    "        self.final = final\n",
    "        self.clf = []          \n",
    "    \n",
    "    def oneFit(self, i):\n",
    "        if len(set(self.y[:, i])) == 2:\n",
    "            #return SVC(C = 1e-3, probability = True).fit(self.X, self.y[:, i])\n",
    "            return LinearSVC(C = self.param).fit(self.X, self.y[:, i])\n",
    "            #return Ridge().fit(self.X, self.y[:, i])\n",
    "            #return RidgeClassifier().fit(self.X, self.y[:, i])\n",
    "            #return BernoulliNB(alpha = 0.01).fit(self.X, self.y[:, i])\n",
    "            #return LinearRegression().fit(self.X, self.y[:, i])\n",
    "            #return LogisticRegression().fit(self.X, self.y[:, i])\n",
    "            #return SGDClassifier(loss = 'perceptron', penalty = 'elasticnet', n_iter = 50).fit(self.X, self.y[:, i])\n",
    "        \n",
    "    def fit(self):\n",
    "        class_pool = Pool(processes = N_PROCS)\n",
    "        self.clf = class_pool.map(unwrapLS, zip([self] * 200, array(range(200))))\n",
    "        class_pool.close()\n",
    "        class_pool.join()            \n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted = []\n",
    "        for i in range(200):\n",
    "            if len(set(self.y[:, i])) == 2:\n",
    "                pred = self.clf[i].decision_function(X)\n",
    "                #pred = self.clf[i].predict(X)\n",
    "                #pred = self.clf[i].predict_proba(X)[:, 0]\n",
    "            else:\n",
    "                pred = [-10] * shape(X)[0]\n",
    "\n",
    "            predicted.append(pred)\n",
    "        del self.clf\n",
    "        gc.collect()\n",
    "        \n",
    "        return array(predicted).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21345, 161)\n"
     ]
    }
   ],
   "source": [
    "# Selecting training data\n",
    "X_train, X_test, y_train, y_test = train_test_split (X,y,train_size=0.1, random_state=222)\n",
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the mode\n",
      "4.18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Classifier\n",
    "# 40 minutes - full run\n",
    "# preprocess\n",
    "# 4 minutes\n",
    "import time\n",
    "\n",
    "print (\"fitting the mode\")\n",
    "start_time = time.time()\n",
    "\n",
    "xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \n",
    "xgb.fit(X_train, y_train)\n",
    "elapsed_time = round((time.time() - start_time)/60,2)\n",
    "\n",
    "print (elapsed_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
